{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Computing in Julia "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why should you write GPU code in Julia \n",
    "    1. Simple interface\n",
    "    2. Write GPU kernel in Julia \n",
    "    3. Comparible Speed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using GPU Packages\n",
    "    1. JuliaGPU github page lists all the GPU packages you can use for CUDA and OpenCL. \n",
    "    2. CuArrays and CLArrays \n",
    "    3. GPUArrays \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using CuArrays \n",
    "\n",
    "# Data Transfer \n",
    "a = rand(100,100)\n",
    "b = rand(100,100)\n",
    "d_a = CuArray(a)\n",
    "d_b = CuArray(b)\n",
    "\n",
    "# Multiple Dispatch\n",
    "result = collect(d_a * d_b)\n",
    "\n",
    "#explicit calling package function\n",
    "result = collect(CuArrays.CUBLAS.gemm('N', 'N', d_a,d_b))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Writing your own GPU code\n",
    "    1. Use CUDAnative and CUDAdrv \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Transfer \n",
    "\n",
    "a = rand(100,100)\n",
    "b = rand(100,100)\n",
    "d_a = CuArray(a)\n",
    "d_b = CuArray(b)\n",
    "\n",
    "# Thread configuration\n",
    "dev = device()\n",
    "threads = attribute(dev, CUDAdrv.WARP_SIZE)\n",
    "blocks = min(Int(ceil(ndrange/threads)), attribute(dev, CUDAdrv.MAX_GRID_DIM_X))\n",
    "\n",
    "# Writing GPU kernel\n",
    "function lod_kernel(input, ndrange,n) \n",
    "    tid = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
    "    if(tid < ndrange+1)\n",
    "        r_square = (input[tid]/n)^2\n",
    "        input[tid] = (-n/Float32(2.0)) * CUDAnative.log(Float32(1.0)-r_square)\n",
    "    end \n",
    "    return\n",
    "end\n",
    "\n",
    "# Calling Function \n",
    "@cuda blocks=blocks threads=threads lod_kernel(d_r, ndrange,n)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
